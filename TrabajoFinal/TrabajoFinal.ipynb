{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carga de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set_orig = datasets.FashionMNIST('MNIST_data/', download=True, train=True , transform=transform)\n",
    "valid_set_orig = datasets.FashionMNIST('MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CustomDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = output = self.dataset[idx][0]\n",
    "        return input, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una época de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Probablemente tenga que agregar para que compute la accuracy\n",
    "def train_step(model, dataloader, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Trains the model for ONE epoch = goes over the dataset one time using the batches.\n",
    "    \"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "    \n",
    "    model_device = next(model.parameters()).device\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(model_device), y.to(model_device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch {batch} of {num_batches}. Loss in batch: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación post época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Probablemente tenga que agregar para que compute la accuracy. Capaz con\n",
    "## un if en la función de pérdida\n",
    "\n",
    "def validate_step(model, dataloader, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model_device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(model_device), y.to(model_device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            total_loss += loss_fn(y_pred, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop de entrenamiento - validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_loop(\n",
    "    model, train_dataloader, valid_dataloader, loss_fn, optimizer, epochs\n",
    "):\n",
    "    train_avg_losses_training, train_avg_losses, valid_avg_losses = [], [], []\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        tqdm.write(f\"Epoch {epoch}\")\n",
    "        train_avg_loss_training = train_step(model, train_dataloader, loss_fn, optimizer)\n",
    "\n",
    "        train_avg_loss = validate_step(model, train_dataloader, loss_fn)\n",
    "        valid_avg_loss = validate_step(model, valid_dataloader, loss_fn)\n",
    "\n",
    "        tqdm.write(f\"Train avg loss: {train_avg_loss:.6f}\")\n",
    "        tqdm.write(f\"Valid avg loss: {valid_avg_loss:.6f}\")\n",
    "        tqdm.write(\"----------------------------------------------------------------\")\n",
    "\n",
    "        train_avg_losses_training.append(train_avg_loss_training)\n",
    "        train_avg_losses.append(train_avg_loss)\n",
    "        valid_avg_losses.append(valid_avg_loss)\n",
    "\n",
    "    print(f\"Training finished! Trained for {epoch} epochs.\")\n",
    "    print(\n",
    "        f\"Final results from epoch {epoch}:\\n\"\n",
    "        f\"  - Train avg loss: {train_avg_loss:.6f}\\n\"\n",
    "        f\"  - Valid avg loss: {valid_avg_loss:.6f}\"\n",
    "    )\n",
    "    return model, train_avg_losses_training, train_avg_losses, valid_avg_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_plot(\n",
    "    train_avg_losses_training, train_avg_losses, valid_avg_losses\n",
    "):\n",
    "    epochs = len(train_avg_losses)\n",
    "    epochs_range = range(epochs)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, train_avg_losses_training, label=\"Durante la época\", linestyle=\"--\", color=\"blue\")\n",
    "    plt.plot(epochs_range, train_avg_losses, label=\"Entrenamiento\", linestyle=\"-\", color=\"green\")\n",
    "    plt.plot(epochs_range, valid_avg_losses, label=\"Validación\", linestyle=\":\", color=\"red\")\n",
    "    \n",
    "    plt.title(\"Pérdidas durante el entrenamiento\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Pérdida promedio por lote\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagen original y reconstruida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_orig_predicted(model, train_set, num_samples=3):\n",
    "    model_device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    num_samples = 2\n",
    "    fig, axes = plt.subplots(nrows=num_samples, ncols=2, figsize=(8, 2*num_samples))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "        input = train_set[sample_idx][0].unsqueeze(1).to(model_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input).squeeze(1).cpu().numpy()\n",
    "\n",
    "        # Plot original image\n",
    "        ax_orig = axes[i, 0]\n",
    "        ax_orig.imshow(input.squeeze().cpu().numpy(), cmap='gray')\n",
    "        ax_orig.axis('off')\n",
    "        ax_orig.set_title(f\"Original {sample_idx}\")\n",
    "        \n",
    "        # Plot predicted image\n",
    "        ax_pred = axes[i, 1]\n",
    "        ax_pred.imshow(output.squeeze(), cmap='gray')\n",
    "        ax_pred.axis('off')\n",
    "        ax_pred.set_title(f\"Reconstructed {sample_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-convolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1 \\right\\rfloor\n",
    "\\\\\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1 \\right\\rfloor\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_conv_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    h_out = int(((h_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    w_out = int(((w_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-convolución transpuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n",
    "\\\\\n",
    "W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_transconv_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    output_padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    h_out = (h_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1\n",
    "    w_out = (w_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1 \\right\\rfloor\n",
    "\\\\\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1 \\right\\rfloor\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_maxpool_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=None,\n",
    "    padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    if stride is None:\n",
    "        stride = kernel_size\n",
    "    h_out = int(((h_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    w_out = int(((w_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Red Neuronal Autoencoder Convolucional de varias capas**\n",
    "Defina y cree una red neuronal autoenconder convolucional. El autoencoder debe poseer dos módulos, un\n",
    "encoder y un decoder. \n",
    "* El encoder tienen que tener al menos dos capas convolucionales 2D y una lineal.\n",
    "* El decoder tiene que realizar una transformación aproximadamente inversa, por ejemplo, utilizando\n",
    "primero una capa lineal y luego dos convolucionales traspuestas.\n",
    "Recuerde incluir dropout, si es que lo considera necesario, y elegir adecuadamente el tipo de unidades de\n",
    "activación de la capa de salida. No utilice dropout en la capa de salida. Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1:    (1, 28, 28) -> (16, 26, 26)\n",
      "MaxPool1: (16, 26, 26) -> (16, 13, 13)\n",
      "\n",
      "Conv2:    (16, 13, 13) -> (32, 11, 11)\n",
      "MaxPool2: (32, 11, 11) -> (32, 5, 5)\n",
      "\n",
      "Final encoder shape: (32, 5, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernels       = [3 , 3 ]\n",
    "paddings      = [0 , 0 ]\n",
    "strides       = [1 , 1 ]\n",
    "out_channels  = [16, 32]\n",
    "\n",
    "ch_in, h_in, w_in = 1, 28, 28\n",
    "\n",
    "for i, (kernel_size, padding, stride, out_channel) in enumerate(zip(kernels, paddings, strides, out_channels)):\n",
    "    ch_out, h_out, w_out = post_conv_shape(h_in, w_in, out_channel, kernel_size, stride, padding)\n",
    "    print(f\"Conv{i+1}:    ({ch_in}, {h_in}, {w_in}) -> ({ch_out}, {h_out}, {w_out})\")\n",
    "    ch_in, h_in, w_in = ch_out, h_out, w_out\n",
    "\n",
    "    ch_out, h_out, w_out = post_maxpool_shape(h_in, w_in, out_channel, kernel_size=2)\n",
    "    print(f\"MaxPool{i+1}: ({ch_in}, {h_in}, {w_in}) -> ({ch_out}, {h_out}, {w_out})\\n\")\n",
    "    ch_in, h_in, w_in = ch_out, h_out, w_out\n",
    "\n",
    "print(f\"Final encoder shape: ({ch_out}, {h_out}, {w_out})\")\n",
    "\n",
    "post_transconv_shape(h_in, w_in, 16, kernel_size=3, stride=2, output_padding=2)\n",
    "\n",
    "post_transconv_shape(13, 13, 1, kernel_size=3, stride=2, output_padding=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # First Convolution\n",
    "            # (1,28,28) -> (16,26,26)\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            # (16,26,26) -> (16,13,13)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Second Convolution\n",
    "            # (16,13,13) -> (32,11,11)\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            # (32,11,11) -> (32,5,5)\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            # (32,5,5) -> 32x5x5\n",
    "            nn.Flatten(),\n",
    "            # 32x5x5 -> 32x5x5\n",
    "            nn.Linear(in_features=32*5*5, out_features=32*5*5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # En principio, vamos a pasar de: tamaño post maxpooling a tamaño\n",
    "            # pre convolución\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32,5,5)),\n",
    "            # First Deconvolution\n",
    "            # (35,5,5) -> (16,13,13)\n",
    "            nn.ConvTranspose2d(in_channels=32, out_channels=16, kernel_size=3, stride=2, output_padding=2),\n",
    "            # Secon Deconvolution\n",
    "            # (16,13,13) -> (1,28,28)\n",
    "            nn.ConvTranspose2d(in_channels=16, out_channels=1, kernel_size=3, stride=2, output_padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Entrenando el autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1) Implemente en una función train_loop un loop que itere en modo entrenamiento sobre los batchs\n",
    "o lotes de una época de entrenamiento.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hecho en función `train_step`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2) Implemente en una función eval_loop un loop que itere en modo evaluación sobre los batchs de\n",
    "una  ́epoca de entrenamiento.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hecho en función `validate_step`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3) Inicialize los DataLoaders sobre el conjunto de entranmiento y el conjunto de validación, usando\n",
    "batchs de 100 ejemplos. AYUDA: Crear nuevas clases derivadas de la clase Dataset que sirvan para\n",
    "entrenar autoencoders, i.e. en donde tanto el input como el output sean la misma imagen.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hecho en clase `CustomDataset`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Cree una función de pérdida usando el Error Cuadrático Medio (ECM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Cree un optimizador con un learning rate igual a 10−3. Pruebe con ADAM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Cree una instancia del modelo autoencoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Especifique en que dispositivo (device) va a trabajar. Lo har ́a en una CPU, en una GPU o una\n",
    "TPU?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.8) Implemente un loop que itere sobre épocas de entrenamiento. Este loop debe guardar en listas\n",
    "correspondientes, y en función de las épocas, los promedios del ECM sobre los conjuntos de entrenamiento y validación, inclueyendo los valores incorrectamente estimados del ECM sobre el conjunto de\n",
    "entrenamiento. IMPORTANTE: No olvide copiar los batchs al dispositivo de trabajo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hecho en función `train_validate_loop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9) Entrene y valide el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.10) Grafique los distintos valores del ECM en función de las épocas de entrenamiento. Cual es el\n",
    "número  ́optimo de  ́epocas de entrenamiento? Discuta y comente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.11) Grafique, comparativamente, algunas de las imagenes a predecir vs las imagenes predichas por el\n",
    "modelo entrenado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.12) Repita utilizando variaciones de los hiperparámetros del autencoder. Por ejemplo, utilizando capas lineales de otros tamaños, valores distintos de dropout, otros optimizadores, distintos learning rates,\n",
    "distintas transformaciones convolucionales y convolucionales traspuestas, etc. Que valores de estos hiperparámetros considera los más convenientes? Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3) Definiendo y entrenando un clasificador convolucional reutilizando el encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1) Defina y cree un clasificador convolucional, agregando una capa clasificadora al encoder del\n",
    "autoencoder previamente entrenado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2) Reimplemente las funciones de entrenamiento, teniendo en cuenta que ahora debe incluir el c ́alculo\n",
    "de precisiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3) Cree una función de pérdida usando la Cross Entropy Loss (CEL)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4) Cree una instancia del modelo clasificador."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5) Entrene y valide el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6) Grafique los distintos valores de la CEL y la precisi ́on calculados, en funci ́on de las  ́epocas de\n",
    "entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7) Utilice el conjunto de validaci ́on para calcular una Matriz de confusi ́on. Graf ́ıquela y comente los\n",
    "resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4) Prentrenamiento**\n",
    "Modifique el optimizador para que solo reentrene los par ́ametros de la capa clasificadora, dejando los\n",
    "par ́ametros de la capa codificadora tal como vienen entrenada del el autoencoder convolucional. Repita\n",
    "los experimentos de la parte 3. Qué observa? Comente\n",
    "\n",
    "Ayuda: Se recomienda guardar en archivos los pesos de las distintas capas de las redes entrenadas para\n",
    "que puedan ser reutilizadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "redes-neuronales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
