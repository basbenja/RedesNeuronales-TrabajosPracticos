{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchinfo import summary\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "HOST = \"127.0.0.1\"\n",
    "PORT = 8080\n",
    "TRACKING_SERVER_URI = f\"http://{HOST}:{PORT}\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_SERVER_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.exceptions\n",
    "\n",
    "EXPERIMENT_DESCRIPPTION = (\n",
    "    \"Convolutional Autoencoder with PyTorch and MNIST dataset\"\n",
    ")\n",
    "\n",
    "EXPERIMENT_TAGS = {\n",
    "    \"project_name\": \"NeuralNetworks_FAMAF_2024\",\n",
    "    \"architecture\": \"ConvolutionalAutoencoder\",\n",
    "    \"author\": \"bbas\",\n",
    "    \"mlflow.note.content\": EXPERIMENT_DESCRIPPTION\n",
    "}\n",
    "\n",
    "try:\n",
    "    mlflow.create_experiment(name=\"ConvAutoencoder-FashionMNIST\", tags=EXPERIMENT_TAGS)\n",
    "except mlflow.exceptions.RestException as e:\n",
    "    print(e)\n",
    "mlflow.set_experiment(\"ConvAutoencoder-FashionMNIST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Carga de Datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_set_orig = datasets.FashionMNIST('MNIST_data/', download=True, train=True , transform=transform)\n",
    "valid_set_orig = datasets.FashionMNIST('MNIST_data/', download=True, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **CustomDataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = output = self.dataset[idx][0]\n",
    "        return input, output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Funciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Una época de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    Trains the model for ONE epoch = goes over the dataset one time using the batches.\n",
    "    \"\"\"\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    is_classification = isinstance(loss_fn, nn.CrossEntropyLoss)\n",
    "    total_acc = 0 if is_classification else None\n",
    "    total_loss = 0\n",
    "    \n",
    "    model_device = next(model.parameters()).device\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(model_device), y.to(model_device)\n",
    "\n",
    "        y_pred = model(X)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if is_classification:\n",
    "            total_acc += (y_pred.argmax(1) == y).float().sum().item()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch {batch} of {num_batches}. Loss in batch: {loss.item():.4f}\")\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    acc = total_acc / size if is_classification else None\n",
    "\n",
    "    return acc, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación post época"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, dataloader, loss_fn):\n",
    "    num_batches = len(dataloader)\n",
    "    size = len(dataloader.dataset)\n",
    "    \n",
    "    is_classification = isinstance(loss_fn, nn.CrossEntropyLoss)\n",
    "    total_acc = 0 if is_classification else None\n",
    "    total_loss = 0\n",
    "\n",
    "    model_device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(model_device), y.to(model_device)\n",
    "\n",
    "            y_pred = model(X)\n",
    "            total_loss += loss_fn(y_pred, y).item()\n",
    "\n",
    "            if is_classification:\n",
    "                total_acc += (y_pred.argmax(1) == y).float().sum().item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    acc = total_acc / size if is_classification else None\n",
    "\n",
    "    return acc, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping basado en loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping():\n",
    "    def __init__(self, delta=0.0001, patience=10):\n",
    "        self.best_loss = np.inf\n",
    "        self.best_epoch = 0\n",
    "        self.best_model = None\n",
    "        self.delta = delta\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "    \n",
    "    def update(self, model, epoch, loss):\n",
    "        early_stop = False\n",
    "        if loss < self.best_loss - self.delta:\n",
    "            self.best_loss = loss\n",
    "            self.best_epoch = epoch\n",
    "            self.best_model = model.state_dict()\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"EarlyStopping counter: {self.counter} out of {self.patience}\")\n",
    "            if self.counter == self.patience:\n",
    "                early_stop = True\n",
    "                print(f\"EarlyStopping: Stopped training at epoch {epoch}.\")\n",
    "        return early_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop de entrenamiento - validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_hyperparams(hyperparams):\n",
    "    mlflow.log_params(hyperparams)\n",
    "\n",
    "def log_model_architecture(model):\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = Path(tmp, \"model_architecture.txt\")\n",
    "        path.write_text(str(model))\n",
    "        mlflow.log_artifact(path)\n",
    "\n",
    "def train_validate_loop(\n",
    "    model, train_loader, valid_loader, loss_fn, optimizer, epochs, extra_hyperparams={},\n",
    "    early_stopper=None,\n",
    "):\n",
    "    is_classification = isinstance(loss_fn, nn.CrossEntropyLoss)\n",
    "    \n",
    "    hyperparams = {\n",
    "        \"max_epochs\": epochs,\n",
    "        \"batch_size\": train_loader.batch_size,\n",
    "        \"optimizer\": optimizer.__class__.__name__,\n",
    "        \"learning_rate\": optimizer.defaults['lr'],\n",
    "        \"loss_function\": loss_fn.__class__.__name__,\n",
    "        \"early_stopper\": {\n",
    "            \"enabled\": early_stopper is not None,\n",
    "            \"patience\": early_stopper.patience if early_stopper else None,\n",
    "            \"delta\": early_stopper.delta if early_stopper else None\n",
    "        },\n",
    "        **extra_hyperparams\n",
    "    }\n",
    "    log_hyperparams(hyperparams)\n",
    "    log_model_architecture(model)\n",
    "\n",
    "    accs_training, train_accs, valid_accs = ([], [], []) if is_classification else None, None, None\n",
    "    avg_losses_training, train_avg_losses, valid_avg_losses = ([], [], [])\n",
    "\n",
    "    for epoch in tqdm(range(1, epochs+1)):\n",
    "        tqdm.write(f\"Epoch {epoch}\")\n",
    "        acc_training, avg_loss_training = train_step(model, train_loader, loss_fn, optimizer)\n",
    "\n",
    "        train_acc, train_avg_loss = validate_step(model, train_loader, loss_fn)\n",
    "        valid_acc, valid_avg_loss = validate_step(model, valid_loader, loss_fn)\n",
    "\n",
    "        avg_losses_training.append(avg_loss_training)\n",
    "        train_avg_losses.append(train_avg_loss)\n",
    "        valid_avg_losses.append(valid_avg_loss)\n",
    "        mlflow.log_metric(\"Average Loss during Training\", f\"{avg_loss_training:.6f}\", step=epoch)\n",
    "        mlflow.log_metric(\"Average Loss in Training Set\", f\"{train_avg_loss:.6f}\", step=epoch)\n",
    "        mlflow.log_metric(\"Average Loss in Validation Set\", f\"{valid_avg_loss:.6f}\", step=epoch)\n",
    "        tqdm.write(f\"Train avg loss: {train_avg_loss:.6f} | Valid avg loss: {valid_avg_loss:.6f}\")\n",
    "        \n",
    "        if is_classification:\n",
    "            accs_training.append(acc_training)\n",
    "            train_accs.append(train_acc)\n",
    "            valid_accs.append(valid_acc)\n",
    "            mlflow.log_metric(\"Accuracy during Training\", f\"{acc_training:.6f}\", step=epoch)\n",
    "            mlflow.log_metric(\"Accuracy in Training Set\", f\"{train_acc:.6f}\", step=epoch)\n",
    "            mlflow.log_metric(\"Accuracy in Validation Set\", f\"{valid_acc:.6f}\", step=epoch)\n",
    "            tqdm.write(f\"Train accuracy: {train_acc:.6f} | Valid accuracy: {valid_acc:.6f}\")\n",
    " \n",
    "        if early_stopper and early_stopper.update(model, epoch, valid_avg_loss):\n",
    "            break\n",
    "\n",
    "        tqdm.write(\"----------------------------------------------------------------\")\n",
    "\n",
    "    mlflow.log_metric(\"Last Epoch\", epoch)\n",
    "    print(f\"Training finished! Trained for {epoch} epochs.\")\n",
    "    print(\n",
    "        f\"Final results from epoch {epoch}:\\n\"\n",
    "        f\"  - Train avg loss: {train_avg_loss:.6f}\\n\"\n",
    "        f\"  - Valid avg loss: {valid_avg_loss:.6f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'model': model,\n",
    "        'avg_losses_training': avg_losses_training,\n",
    "        'train_avg_losses': train_avg_losses,\n",
    "        'valid_avg_losses': valid_avg_losses,\n",
    "        'accs_training': accs_training,\n",
    "        'train_accs': train_accs,\n",
    "        'valid_accs': valid_accs\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gráfico de accuracy y pérdidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def losses_plot(avg_losses_training, train_avg_losses, valid_avg_losses, show=False):\n",
    "    epochs = len(train_avg_losses)\n",
    "    epochs_range = range(epochs)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, avg_losses_training, label=\"Durante la época\", linestyle=\"--\", color=\"blue\")\n",
    "    plt.plot(epochs_range, train_avg_losses, label=\"Entrenamiento\", linestyle=\"-\", color=\"green\")\n",
    "    plt.plot(epochs_range, valid_avg_losses, label=\"Validación\", linestyle=\":\", color=\"red\")\n",
    "    \n",
    "    plt.title(\"Pérdidas durante el entrenamiento\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Pérdida promedio por lote\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = Path(tmp, \"losses_plot.png\")\n",
    "        plt.savefig(path)\n",
    "        mlflow.log_artifact(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "def accs_plot(accs_training, train_accs, valid_accs, show=False):\n",
    "    epochs = len(train_accs)\n",
    "    epochs_range = range(epochs)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(epochs_range, accs_training, label=\"Durante la época\", linestyle=\"--\", color=\"blue\")\n",
    "    plt.plot(epochs_range, train_accs, label=\"Entrenamiento\", linestyle=\"-\", color=\"green\")\n",
    "    plt.plot(epochs_range, valid_accs, label=\"Validación\", linestyle=\":\", color=\"red\")\n",
    "    \n",
    "    plt.title(\"Accuracy durante el entrenamiento\")\n",
    "    plt.xlabel(\"Épocas\")\n",
    "    plt.ylabel(\"Accuracy (exactitud)\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = Path(tmp, \"accuracy_plot.png\")\n",
    "        plt.savefig(path)\n",
    "        mlflow.log_artifact(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagen original y reconstruida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_orig_predicted(model, train_set, num_samples=3, show=False):\n",
    "    model_device = next(model.parameters()).device\n",
    "    model.eval()\n",
    "\n",
    "    num_samples = 2\n",
    "    fig, axes = plt.subplots(nrows=num_samples, ncols=2, figsize=(8, 2*num_samples))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
    "        input = train_set[sample_idx][0].unsqueeze(1).to(model_device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(input).squeeze(1).cpu().numpy()\n",
    "\n",
    "        # Plot original image\n",
    "        ax_orig = axes[i, 0]\n",
    "        ax_orig.imshow(input.squeeze().cpu().numpy(), cmap='gray')\n",
    "        ax_orig.axis('off')\n",
    "        ax_orig.set_title(f\"Original {sample_idx}\")\n",
    "        \n",
    "        # Plot predicted image\n",
    "        ax_pred = axes[i, 1]\n",
    "        ax_pred.imshow(output.squeeze(), cmap='gray')\n",
    "        ax_pred.axis('off')\n",
    "        ax_pred.set_title(f\"Reconstructed {sample_idx}\")\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as tmp:\n",
    "        path = Path(tmp, \"orig_predicted_plot.png\")\n",
    "        plt.savefig(path)\n",
    "        mlflow.log_artifact(path)\n",
    "    \n",
    "    if show:\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-convolución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1 \\right\\rfloor\n",
    "\\\\\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1 \\right\\rfloor\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_conv_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    h_out = int(((h_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    w_out = int(((w_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-convolución transpuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = (H_{in} - 1) \\times \\text{stride}[0] - 2 \\times \\text{padding}[0] + \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) + \\text{output\\_padding}[0] + 1\n",
    "\\\\\n",
    "W_{out} = (W_{in} - 1) \\times \\text{stride}[1] - 2 \\times \\text{padding}[1] + \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) + \\text{output\\_padding}[1] + 1\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_transconv_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    output_padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    h_out = (h_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1\n",
    "    w_out = (w_in - 1) * stride - 2 * padding + dilation * (kernel_size - 1) + output_padding + 1\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape post-max pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shape:\n",
    "* Input: $(C_{in}, H_{in}, W_{in})$\n",
    "* Output: $(C_{out}, H_{out}, W_{out})$,\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{align*}\n",
    "H_{out} = \\left\\lfloor \\frac{H_{in} + 2 \\times \\text{padding}[0] - \\text{dilation}[0] \\times (\\text{kernel\\_size}[0] - 1) - 1}{\\text{stride}[0]} + 1 \\right\\rfloor\n",
    "\\\\\n",
    "W_{out} = \\left\\lfloor \\frac{W_{in} + 2 \\times \\text{padding}[1] - \\text{dilation}[1] \\times (\\text{kernel\\_size}[1] - 1) - 1}{\\text{stride}[1]} + 1 \\right\\rfloor\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_maxpool_shape(\n",
    "    h_in,\n",
    "    w_in,\n",
    "    out_channels,\n",
    "    kernel_size,\n",
    "    stride=None,\n",
    "    padding=0,\n",
    "    dilation=1\n",
    "):\n",
    "    if stride is None:\n",
    "        stride = kernel_size\n",
    "    h_out = int(((h_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    w_out = int(((w_in + 2 * padding - dilation * (kernel_size - 1) - 1) / stride) + 1)\n",
    "    return out_channels, h_out, w_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1) Red Neuronal Autoencoder Convolucional de varias capas**\n",
    "Defina y cree una red neuronal autoenconder convolucional. El autoencoder debe poseer dos módulos, un\n",
    "encoder y un decoder. \n",
    "* El encoder tienen que tener al menos dos capas convolucionales 2D y una lineal.\n",
    "* El decoder tiene que realizar una transformación aproximadamente inversa, por ejemplo, utilizando\n",
    "primero una capa lineal y luego dos convolucionales traspuestas.\n",
    "Recuerde incluir dropout, si es que lo considera necesario, y elegir adecuadamente el tipo de unidades de\n",
    "activación de la capa de salida. No utilice dropout en la capa de salida. Por qué?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out channels: **1 -> 8 -> 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder2Layers_v1(nn.Module):\n",
    "    def __init__(self, add_linear, p):\n",
    "        super().__init__()\n",
    "        self._add_linear = add_linear\n",
    "        self._dropout = p\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3),    # (1,28,28) -> (8,26,26)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (8,26,26) -> (8,13,13)\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),   # (8,13,13) -> (16,11,11)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2)    # (16,11,11) -> (16,5,5)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),    # (16,5,5) -> 16x5x5\n",
    "            nn.Linear(in_features=16*5*5, out_features=16*5*5),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(16,5,5)),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # nn.Unflatten(dim=1, unflattened_size=(16,5,5)),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, out_channels=8, kernel_size=3, stride=3, padding=1\n",
    "            ),    # (16,5,5) -> (8,13,13)\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8, out_channels=1, kernel_size=4, stride=2, padding=0\n",
    "            ),    # (8,13,13) -> (1,28,28)\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if self._add_linear:\n",
    "            x = self.linear(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder2Layers_v2(nn.Module):\n",
    "    def __init__(self, add_linear, p):\n",
    "        super().__init__()\n",
    "        self._add_linear = add_linear\n",
    "        self._dropout = p\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, padding=1),    # (1,28,28) -> (8,28,28)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (8,26,26) -> (8,14,14)\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1),   # (8,14,14) -> (16,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2)    # (16,14,14) -> (16,7,7)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),    # (16,7,7) -> 16*7*7\n",
    "            nn.Linear(in_features=16*7*7, out_features=16*7*7),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.Unflatten(dim=1, unflattened_size=(16,7,7)),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, out_channels=8, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),    # (16,7,7) -> (8,14,14)\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8, out_channels=1, kernel_size=3, stride=2, padding=1, output_padding=1\n",
    "            ),    # (8,14,14) -> (1,28,28)\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if self._add_linear:\n",
    "            x = self.linear(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out channels: **1 -> 8 -> 16 -> 32**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder3Layers_v1(nn.Module):\n",
    "    def __init__(self, add_linear, p):\n",
    "        super().__init__()\n",
    "        self._add_linear = add_linear\n",
    "        self._dropout = p\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3),    # (1,28,28) -> (8,26,26)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (8,26,26) -> (8,13,13)\n",
    "\n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),   # (8,13,13) -> (16,11,11)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (16,11,11) -> (16,5,5)\n",
    "            \n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3),   # (16,5,5) -> (32,3,3)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2)    # (32,3,3) -> (32,1,1)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),    # (32,1,1) -> 32*1*1\n",
    "            nn.Linear(in_features=32*1*1, out_features=32*1*1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(dim=1, unflattened_size=(32, 1, 1)),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=32, out_channels=16, kernel_size=5\n",
    "            ),    # (32,1,1) -> (16,5,5)\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, out_channels=8, kernel_size=3, stride=3, padding=1\n",
    "            ),    # (16,5,5) -> (8,13,13)\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8, out_channels=1, kernel_size=4, stride=2, padding=0\n",
    "            ),    # (8,13,13) -> (1,28,28)\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if self._add_linear:\n",
    "            x = self.linear(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out channels: **1 -> 4 -> 8 -> 16**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvAutoencoder3Layers_v2(nn.Module):\n",
    "    def __init__(self, add_linear, p):\n",
    "        super().__init__()\n",
    "        self._add_linear = add_linear\n",
    "        self._dropout = p\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3),    # (1,28,28) -> (4,26,26)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (4,26,26) -> (4,13,13)\n",
    "\n",
    "            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=1),   # (4,13,13) -> (8,13,13)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2),    # (8,13,13) -> (8,6,6)\n",
    "            \n",
    "            nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3),   # (8,6,6) -> (16,4,4)\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p),\n",
    "            nn.MaxPool2d(kernel_size=2)    # (16,4,4) -> (16,2,2)\n",
    "        )\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Flatten(),    # (16,2,2) -> 16*2*2\n",
    "            nn.Linear(in_features=16*2*2, out_features=16*2*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(dim=1, unflattened_size=(16, 2, 2)),\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=16, out_channels=8, kernel_size=5\n",
    "            ),    # (16, 2, 2) -> (8, 6, 6)\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=8, out_channels=4, kernel_size=3, stride=2\n",
    "            ),    # (8, 6, 6) -> (4, 13, 13)\n",
    "            \n",
    "            nn.ConvTranspose2d(\n",
    "                in_channels=4, out_channels=1, kernel_size=4, stride=2\n",
    "            ),    # (4, 13, 13) -> (1, 28, 28)\n",
    "            \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        if self._add_linear:\n",
    "            x = self.linear(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2) Entrenando el autoencoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implemente en una función train_loop un loop que itere en modo entrenamiento sobre los batchs\n",
    "o lotes de una época de entrenamiento.\n",
    "2. Implemente en una función eval_loop un loop que itere en modo evaluación sobre los batchs de\n",
    "una  ́epoca de entrenamiento.\n",
    "3. Inicialize los DataLoaders sobre el conjunto de entranmiento y el conjunto de validación, usando\n",
    "batchs de 100 ejemplos. AYUDA: Crear nuevas clases derivadas de la clase Dataset que sirvan para\n",
    "entrenar autoencoders, i.e. en donde tanto el input como el output sean la misma imagen.\n",
    "4. Cree una función de pérdida usando el Error Cuadrático Medio (ECM).\n",
    "5. Cree un optimizador con un learning rate igual a 10−3. Pruebe con ADAM.\n",
    "6. Cree una instancia del modelo autoencoder.\n",
    "7. Especifique en que dispositivo (device) va a trabajar. Lo har ́a en una CPU, en una GPU o una\n",
    "TPU?\n",
    "8. Implemente un loop que itere sobre épocas de entrenamiento. Este loop debe guardar en listas\n",
    "correspondientes, y en función de las épocas, los promedios del ECM sobre los conjuntos de entrenamiento y validación, inclueyendo los valores incorrectamente estimados del ECM sobre el conjunto de\n",
    "entrenamiento. IMPORTANTE: No olvide copiar los batchs al dispositivo de trabajo.\n",
    "9. Entrene y valide el modelo.\n",
    "10. Grafique los distintos valores del ECM en función de las épocas de entrenamiento. Cual es el\n",
    "número  ́optimo de  ́epocas de entrenamiento? Discuta y comente.\n",
    "11. Grafique, comparativamente, algunas de las imagenes a predecir vs las imagenes predichas por el\n",
    "modelo entrenado.\n",
    "12. Repita utilizando variaciones de los hiperparámetros del autencoder. Por ejemplo, utilizando capas lineales de otros tamaños, valores distintos de dropout, otros optimizadores, distintos learning rates,\n",
    "distintas transformaciones convolucionales y convolucionales traspuestas, etc. Que valores de estos hiperparámetros considera los más convenientes? Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(\n",
    "    CustomDataset(train_set_orig), batch_size=batch_size, shuffle=True, num_workers=4\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    CustomDataset(valid_set_orig), batch_size=batch_size, shuffle=False, num_workers=4\n",
    ")\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 50\n",
    "lr = 10e-3\n",
    "dropout = 0\n",
    "add_linear = True\n",
    "\n",
    "extra_hyperparms = {\n",
    "    \"dropout\": dropout,\n",
    "    \"add_linear\": add_linear\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder2Layers_v1(add_linear=add_linear, p=dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "with mlflow.start_run(run_name=f\"run_{timestamp}\"):\n",
    "    results = train_validate_loop(\n",
    "        model, train_loader, valid_loader, loss_fn, optimizer, epochs, extra_hyperparms\n",
    "    )\n",
    "\n",
    "    mlflow.pytorch.log_model(results['model'], \"models\")\n",
    "    \n",
    "    losses_plot(\n",
    "        results['avg_losses_training'],\n",
    "        results['train_avg_losses'],\n",
    "        results['valid_avg_losses']\n",
    "    )\n",
    "    plot_orig_predicted(model, train_set_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvAutoencoder2Layers_v2(add_linear=add_linear, p=dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "with mlflow.start_run(run_name=f\"run_{timestamp}\"):\n",
    "    results = train_validate_loop(\n",
    "        model, train_loader, valid_loader, loss_fn, optimizer, epochs, extra_hyperparms\n",
    "    )\n",
    "    \n",
    "    mlflow.pytorch.log_model(results['model'], \"models\")\n",
    "    \n",
    "    losses_plot(\n",
    "        results['avg_losses_training'],\n",
    "        results['train_avg_losses'],\n",
    "        results['valid_avg_losses']\n",
    "    )    \n",
    "    plot_orig_predicted(model, train_set_orig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3) Definiendo y entrenando un clasificador convolucional reutilizando el encoder**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Defina y cree un clasificador convolucional, agregando una capa clasificadora al encoder del\n",
    "autoencoder previamente entrenado.\n",
    "2. Reimplemente las funciones de entrenamiento, teniendo en cuenta que ahora debe incluir el cálculo\n",
    "de precisiones.\n",
    "3. Cree una función de pérdida usando la Cross Entropy Loss (CEL).\n",
    "4. Cree una instancia del modelo clasificador.\n",
    "5. Entrene y valide el modelo.\n",
    "6. Grafique los distintos valores de la CEL y la precisión calculados, en función de las  ́epocas de\n",
    "entrenamiento.\n",
    "7. Utilice el conjunto de validación para calcular una Matriz de confusión. Grafíquela y comente los\n",
    "resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4) Prentrenamiento**\n",
    "Modifique el optimizador para que solo reentrene los par ́ametros de la capa clasificadora, dejando los\n",
    "par ́ametros de la capa codificadora tal como vienen entrenada del el autoencoder convolucional. Repita\n",
    "los experimentos de la parte 3. Qué observa? Comente\n",
    "\n",
    "Ayuda: Se recomienda guardar en archivos los pesos de las distintas capas de las redes entrenadas para\n",
    "que puedan ser reutilizadas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RedesNeuronales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
